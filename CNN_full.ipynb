{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d58d8d2-5956-4b53-8a3e-79c842d5d3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec, FastText\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "\n",
    "\n",
    "import gensim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e594c90-124d-4975-a4d9-7342b7ca1d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test_clean.csv')\n",
    "train_data = pd.read_csv('train_clean.csv')\n",
    "\n",
    "train_data_sample = train_data\n",
    "test_data_sample = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "782c308f-52af-458f-8086-e93cf66c8708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frankenstein w2v into CNN, CNN needs numerical input\n",
    "\n",
    "sample_1_list = (train_data_sample['text']).tolist()\n",
    "#print(sample_1_list)\n",
    "sentences = sample_1_list\n",
    "\n",
    "\n",
    "sample_2_list = (test_data_sample['text']).tolist()\n",
    "#print(sample_1_list)\n",
    "sentences2 = sample_2_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0eaacfd-95b9-4cc2-b889-e07f4a44044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentences =' '.join(map(str, sentences))\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    #sentence = sentence.strip('.,();:')\n",
    "    sentence = sentence.replace(',','')\n",
    "    sentence = sentence.replace('.','')\n",
    "    sentence = sentence.replace('(','')\n",
    "    sentence = sentence.replace(')','')\n",
    "    sentence = sentence.replace(';','')\n",
    "    sentence = sentence.replace(':','')\n",
    "    sentence = sentence.split()\n",
    "    \n",
    "    sentences[i] = sentence\n",
    "    \n",
    "#sentences = sentences.split()\n",
    "#sentences\n",
    "\n",
    "\n",
    "for i, sentence2 in enumerate(sentences2):\n",
    "    #sentence = sentence.strip('.,();:')\n",
    "    sentence2 = sentence2.replace(',','')\n",
    "    sentence2 = sentence2.replace('.','')\n",
    "    sentence2 = sentence2.replace('(','')\n",
    "    sentence2 = sentence2.replace(')','')\n",
    "    sentence2 = sentence2.replace(';','')\n",
    "    sentence2 = sentence2.replace(':','')\n",
    "    sentence2 = sentence2.split()\n",
    "    \n",
    "    sentences2[i] = sentence2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2242ec9-9002-4127-b49f-1a8d68847b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(sentences, min_count=1, vector_size = 5)\n",
    "\n",
    "w2v_test = Word2Vec(sentences2, min_count=1, vector_size = 5)\n",
    "\n",
    "#print(w2v.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b614a24c-90f2-4302-83b8-f87b80c7e997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7, 324, 2, 24, 23, 12, 329, 222, 330, 37, 332, 70, 9, 24, 71, 336, 4, 219, 34, 338, 20, 0, 106, 2, 342, 222, 343, 344, 323, 322, 1, 213, 320], [212, 298, 299, 0, 300, 1, 301, 2, 107, 108, 109, 110, 73, 307, 4, 205, 0, 106, 225, 2, 297, 111, 70, 9, 24], [212, 16, 51, 312, 23, 12, 313, 232, 234, 3, 112, 111, 70, 9, 24, 3, 316, 52, 236, 233, 4, 170, 109, 36, 5, 49, 309, 164, 28, 5], [7, 36, 5, 52, 360, 3, 0, 110, 5, 73, 375, 107, 108, 160], [7, 73, 51, 376, 39, 158, 378, 1, 379, 12, 106, 380, 4, 205, 225, 381, 1, 382, 4, 383, 0, 384, 385, 152, 9, 24, 3, 113, 114], [388, 52, 389, 0, 73, 20, 12, 390, 2, 391, 392, 144, 146, 393, 394, 115], [374, 75, 71, 372, 371, 158, 24, 151, 168, 2, 114, 1, 75, 2, 116, 350], [351, 75, 352, 77, 354, 1, 196, 355, 116, 1, 168, 2, 114, 356, 4, 24, 1, 213, 357], [358, 348, 52, 219, 295, 55, 361, 362, 2, 0, 36, 49, 363, 115, 364, 365, 1, 55, 35, 146, 180], [367, 2, 0, 107, 108, 16, 52, 368, 369, 370, 0, 347, 2, 110, 5, 175, 296, 116, 151, 75, 20, 111, 70, 9, 24], [7, 79, 2, 80, 16, 11, 4, 257, 0, 256, 178, 1, 250, 2, 183, 117, 118, 171, 14, 117, 119, 3, 0, 292, 2, 197, 120], [169, 286, 2, 285, 69, 281, 121, 276, 120, 8, 122, 3, 80, 16], [270, 8, 46, 138, 140, 13, 5, 84, 122, 21, 69, 156, 9, 14, 271, 1, 5, 48, 122, 282, 69, 156, 9, 284, 287, 183, 118], [264, 35, 69, 3, 32, 13, 254, 255, 1, 123, 244, 231, 0, 16], [267, 13, 229, 228, 3, 293, 1, 3, 124, 268, 2, 272, 9, 228, 2, 277, 278, 1, 280, 3, 68, 283], [211, 288, 289, 103, 30, 11, 265, 252, 64, 37, 42, 4, 216, 241, 64, 3, 5, 84, 27, 9, 220, 216, 64, 37, 42, 4, 249, 125, 64, 3, 5, 48], [211, 248, 124, 253, 223, 11, 259, 35, 1, 126, 261, 20, 5, 84, 1, 5, 48, 103, 30, 127, 112, 396, 4, 190, 35, 1, 190, 398, 450, 530, 22, 30, 127], [224, 11, 128, 533, 3, 0, 534, 221, 535, 3, 32, 13], [224, 11, 109, 536, 3, 537, 538, 44, 529, 44, 540, 1, 542, 3, 5, 84, 3, 543, 6, 544, 6, 545, 6, 1, 58, 6, 127, 27, 9, 214, 6, 214, 6, 129, 6, 1, 129, 6, 3, 5, 48], [130, 131, 550, 551, 137, 8, 541, 3, 5, 48], [527, 117, 118, 20, 197, 120, 51, 515, 1, 526], [504, 505, 0, 131, 206, 152, 9, 14, 506, 507], [7, 79, 2, 80, 508, 46, 16, 11, 4, 509, 510, 132, 66, 1, 34, 230, 14, 227, 235, 513, 25, 33, 26, 1, 54, 3, 517, 162, 161], [518, 519, 57, 11, 521, 20, 162, 161, 49, 522, 8, 523, 233, 4, 0, 16, 13, 18, 10, 125, 552, 553, 3, 139, 5], [7, 36, 5, 62, 0, 142, 143, 9, 567, 66, 20, 0, 57, 63, 132, 65, 147, 1, 0, 28, 5, 0, 142, 143, 105, 4, 0, 585, 63, 586, 587], [7, 150, 2, 25, 33, 1, 26, 11, 588, 3, 0, 589, 164, 590, 56, 60, 0, 61, 25, 594, 23, 195, 23, 55, 19, 194, 123, 1, 596, 193], [7, 61, 597, 3, 56, 11, 598, 40, 0, 600, 601, 9, 12, 182, 134], [7, 581, 2, 0, 177, 8, 580, 579, 1, 578, 40, 0, 17, 104, 12, 558, 134, 1, 40, 0, 172, 104, 12, 182, 134], [7, 17, 3, 0, 28, 5, 8, 3, 34, 33, 3, 0, 56, 98, 0, 17, 3, 0, 36, 5, 1, 0, 82, 29, 0, 13, 11, 176, 50, 41, 10, 561], [562, 33, 101, 105, 4, 0, 17, 1, 0, 172, 99, 22, 0, 59], [94, 32, 13, 0, 565, 223, 555, 8, 92, 55, 566, 568, 22, 59, 1, 128, 50, 82, 11, 92, 29, 0, 16, 13], [569, 0, 61, 25, 184, 0, 17, 3, 0, 28, 5, 8, 3, 33, 41, 10, 570], [7, 17, 571, 185, 90, 50, 26, 3, 0, 56, 188, 0, 26, 99, 193], [572, 89, 22, 59, 0, 17, 8, 68, 573, 105, 4, 191, 177, 192, 6, 18, 10, 125], [574, 98, 575, 2, 0, 17, 83, 1, 68, 83, 577, 44], [528, 1, 54, 42, 60, 0, 502, 2, 0, 59, 188, 501, 17, 83, 0, 500, 184, 199, 2, 186, 83, 44], [7, 426, 1, 427, 2, 25, 26, 1, 54, 29, 0, 36, 1, 28, 13, 8, 185, 176, 50], [428, 65, 429, 66, 1, 34, 230, 144, 14, 227, 235, 430, 4, 90, 12, 431, 97, 39, 0, 17, 63, 433, 1, 434, 186, 4, 149, 148, 25, 26, 1, 54], [7, 65, 66, 435, 132, 65, 147, 67, 436, 0, 57, 63, 33, 60, 0, 61, 438, 89, 1, 439, 440, 0, 57, 4, 149, 148, 0, 196, 2, 441, 25, 26, 1, 54], [442, 443, 0, 137, 2, 444, 87, 141, 446, 96, 77, 102, 100, 12, 411, 100, 2, 76, 155, 400, 3, 102, 96, 77, 3, 76, 157], [401, 402, 403, 1, 404, 405, 406, 76, 157, 8, 46, 138, 12, 87, 5, 18, 10, 201, 1, 12, 28, 5, 112, 62, 407, 18, 10, 408, 104, 12, 409, 399], [163, 11, 410, 9, 0, 412, 413, 163, 414, 165], [7, 415, 167, 2, 416, 417, 202, 209, 418, 202, 419, 1, 420, 237, 19, 8, 421, 103, 1, 22, 0, 30], [448, 35, 115, 2, 30, 165, 101, 3, 32, 13, 42, 67, 41, 424, 238, 9, 128, 50, 82, 29, 0, 13, 41, 449, 238], [7, 167, 2, 209, 42, 67, 1, 0, 150, 2, 237, 19, 99, 67, 3, 32, 13, 1, 476, 478, 34, 3, 0, 28, 5], [130, 479, 2, 30, 11, 74, 3, 170, 5, 60, 30], [7, 76, 155, 100, 87, 229, 481, 3, 102, 96, 77, 1, 482, 483, 16], [484, 204, 2, 485, 486, 487, 207, 71, 477, 208, 4, 236, 488, 490, 4, 14, 207, 491, 4, 95, 88, 494], [495, 496, 46, 497, 53, 37, 27, 0, 499, 93, 91, 1, 178, 2, 31, 15, 45, 19, 6, 453, 113, 72, 15, 45, 21, 6, 199, 455, 113, 133, 1, 14, 15, 45, 3, 457, 218], [7, 458, 2, 459, 91, 53, 71, 460], [461, 451, 218, 18, 10, 462, 464, 31, 15, 45, 19, 6, 38, 466, 467, 468, 72, 49, 21, 6, 38, 469, 470, 471, 133, 4, 139, 472, 20, 58, 473, 210, 397, 40, 12, 465, 456], [454, 18, 10, 452, 3, 474, 16, 141, 62, 14, 15, 45, 58, 463, 72, 20, 58, 210], [475, 15, 489, 8, 498, 121, 493, 44, 492, 480, 39, 422, 423, 1, 123, 437, 447, 1, 15, 93, 445, 8, 425, 40, 432, 576], [7, 53, 189, 187, 91, 29, 0, 19, 6, 1, 21, 6, 31, 181, 23, 195, 23, 95, 88, 136, 27, 4, 14, 179, 564, 563, 6, 135], [560, 88, 136, 11, 187, 29, 0, 140, 204, 9, 559, 12, 35, 6, 82, 3, 0, 174, 173, 41, 10, 557], [556, 32, 31, 181, 189, 599, 595, 9, 12, 593, 592, 2, 194, 591, 4, 584, 583, 23, 27, 4, 14, 15], [7, 19, 6, 38, 582, 34, 554, 179, 525, 4, 0, 21, 6, 38, 524, 520, 174, 173, 1, 516, 514, 53], [503, 200, 512, 206, 8, 0, 68, 511, 549, 131, 548, 74, 9, 31, 15], [7, 547, 93, 546, 2, 31, 15, 19, 6, 38, 215, 72, 51, 539, 4, 37, 2, 0, 21, 6, 38, 215, 133], [532, 136, 4, 15, 51, 531, 95, 22, 31, 200, 23, 27, 4, 14, 262], [260, 19, 11, 251, 9, 247, 246, 263], [130, 291, 53, 90, 290, 74, 39, 0, 97, 2, 226, 175, 39, 43, 22, 81], [7, 203, 160, 166, 79, 11, 4, 243, 0, 97, 2, 86, 171, 85, 273, 119, 39, 153, 55, 126, 145, 242], [169, 269, 79, 11, 4, 274, 275, 3, 124, 279, 29, 81, 154, 198, 266, 1, 245, 43], [94, 12, 239, 74, 46, 232, 234, 129, 81, 154, 62, 21, 89, 2, 86, 226, 18, 10, 240, 49, 85, 119, 18, 10, 258], [94, 80, 294, 180, 16, 159, 78, 8, 366], [359, 353, 8, 349, 121, 373, 221, 395, 1, 387, 386, 377, 78, 86, 5, 18, 10, 201, 85, 5, 18, 10, 220, 231, 191, 346], [7, 166, 345, 319, 8, 153, 318, 1, 317, 43, 315], [7, 203, 92, 37, 126, 145, 22, 81, 314, 2, 311, 78, 192, 6, 3, 0, 86, 5, 8, 208, 310, 4, 308, 27, 9, 21, 2, 306, 305, 6, 3, 0, 85, 5, 47, 10, 304, 303, 2, 159, 302, 6, 78, 8, 43], [321, 341, 8, 340, 47, 10, 339, 217, 337, 335, 101, 47, 10, 334, 217, 135, 333, 47, 10, 331, 1, 8, 135, 328, 327, 47, 10, 326, 98, 325, 198, 602, 603, 43]]\n"
     ]
    }
   ],
   "source": [
    "sequences_train = []\n",
    "for sentence in sentences:\n",
    "    sequences_train.append(list(map(w2v.wv.key_to_index.get, sentence)))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "sequences_test = []\n",
    "for sentence2 in sentences2:\n",
    "    sequences_test.append(list(map(w2v_test.wv.key_to_index.get, sentence2)))\n",
    "\n",
    "    \n",
    "#print(sequences_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7e8508-bd02-4aa4-8df0-b756f309aecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65bd3fd6-e3b3-4d27-a21a-e166a6e02e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras as keras\n",
    "import tensorflow as tf\n",
    "# pip install tensorflow, keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4848c6ea-5cd0-40ec-856d-7a36c9aa732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa77b567-ff00-46b4-b107-2646869af98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# change to sample when ready to combine from w2v\n",
    "test_x = sequences_test\n",
    "train_x = sequences_train\n",
    "\n",
    "test_y = test_data['category']\n",
    "train_y = train_data['category']\n",
    "                        \n",
    "                        \n",
    "train_y = train_y\n",
    "test_y = test_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b89ea606-b231-461b-99ca-b8ac6f7e3a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dic = {\n",
    "    \"OBJECTIVE\": 0,\n",
    "    \"BACKGROUND\":1,\n",
    "    \"METHODS\":2,\n",
    "    \"RESULTS\":3,\n",
    "    \"CONCLUSIONS\":4\n",
    "}\n",
    "#This applies the dictionary to the data   \n",
    "train_y = train_y.map(cat_dic.get)\n",
    "test_y = test_y.map(cat_dic.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74174008-690d-4a8b-9dac-fa13dce7b7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "\n",
    "# Our dictionary will contain only of the top 7000 words appearing most frequently\n",
    "top_words = 7000\n",
    "\n",
    "\n",
    "# Now we split our data-set into training and test data\n",
    "X_train = train_x\n",
    "y_train = train_y\n",
    "X_test = test_x\n",
    "y_test = test_y\n",
    "\n",
    "\n",
    "\n",
    "# Looking at the nature of training data\n",
    "#print(X_train[0])\n",
    "#print(y_train[0])\n",
    "#print('Shape of training data: ')\n",
    "#print(X_train.shape)\n",
    "#print(y_train.shape)\n",
    "#print('Shape of test data: ')\n",
    "#print(X_test.shape)\n",
    "#print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56d2cd48-6651-4686-8a4b-5deaffcdc444",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([np.array(i) for i in X_train])\n",
    "y_train = np.array([np.array(i) for i in y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "379ca3a6-f1b6-457f-812a-b0f0f505684c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Padding the data samples to a maximum review length in words\n",
    "\n",
    "max_words = 450\n",
    "X_train = pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = pad_sequences(X_test, maxlen=max_words)\n",
    "# Building the CNN Model\n",
    "model = Sequential()      # initilaizing the Sequential nature for CNN model\n",
    "# Adding the embedding layer which will take in maximum of 450 words as input and provide a 32 dimensional output of those words which belong in the top_words dictionary\n",
    "model.add(Embedding(top_words, 32, input_length=max_words))\n",
    "model.add(Conv1D(32, 3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f82aad7-770c-442b-abd6-429054de3390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 450, 32)           224000    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 450, 32)           3104      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 225, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 7200)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 250)               1800250   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 251       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,027,605\n",
      "Trainable params: 2,027,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2a48388-1c01-4d57-abf2-e5eb4b945168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 - 2s - loss: 0.7150 - accuracy: 0.0571 - val_loss: -6.1287e-01 - val_accuracy: 0.1667 - 2s/epoch - 2s/step\n",
      "Epoch 2/2\n",
      "1/1 - 0s - loss: -5.6714e-01 - accuracy: 0.0857 - val_loss: -1.9350e+00 - val_accuracy: 0.1667 - 107ms/epoch - 107ms/step\n",
      "Accuracy: 16.67%\n"
     ]
    }
   ],
   "source": [
    "# Fitting the data onto model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128, verbose=2)\n",
    "# Getting score metrics from our model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "# Displays the accuracy of correct sentiment prediction over test data\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cd9455-2808-4a1d-8a96-60f560afbffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f40fe9-ce80-4411-819e-32dc61267808",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
